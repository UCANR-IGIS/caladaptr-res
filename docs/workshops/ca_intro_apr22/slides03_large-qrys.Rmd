---
title: "<span style='color:#444; font-size:80%;'>Working with Cal-Adapt Climate Data in R: </span><br/>Large Queries"
pagetitle: "Large Queries"
author: "<a href='https://ucanr-igis.github.io/caladaptr/' target='_blank' rel='noopener'><img src='images/caladaptr-hexlogo_173x200.gif' style='height:120px; width:104px; padding:1em;'/></a>"
date: "<div style='width:900px; margin:0 auto;'><img src='images/igis-logo_550x58x256.png' style='padding:1em; float:left;'/><img src='images/cal-adapt-logo.svg' style='height:60px; padding:1em; float:right;'/></div>"
output: 
  slidy_presentation: 
    self_contained: no
    lib_dir: lib
    keep_md: no
    smart: no
    df_print: paged
    css: z_slidy.css
    footer: "<a href='index.html' style='color:#777; margin-left:2em;'>Working with Cal-Adapt Climate Data in R</a>"
    includes:
      in_header: gtag_caladaptr-res.js
---

# Querying Large Data

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caladaptr)
library(DiagrammeR)  ## has a conflict with leaflet, must go high up in the pecking order
library(knitr)
library(kableExtra)
library(magrittr)
library(dplyr)
library(tidyr)
library(sf)
library(leaflet)
library(tmap)
library(htmltools)
```

```{js echo = FALSE}
w3c_slidy.mouse_click_enabled = false;
```

Imagine you want to extract the climate data for 36,000 vernal pool locations.

Issues that arise when querying large number (1000s) of locations:

<div class = "indented1 li-single">
- R tries to load everything in memory   
- long times to download data  
- server overload  
</div>

## General Strategies

<div class = "indented2">

**1) Aggregate point features by LOCA grid cells **

<div class = "indented2">
- The same API call can be used for all points in the same LOCA grid cell
</div>

**2) Download rasters**

<div class = "indented2">
- `ca_getrst_stars()`
- Although it will take longer to download, data extraction and geoprocessing may be faster locally
</div>

**3) Save values in a local SQLite database**

<div class = "indented2">
- `ca_getvals_db()`  
- values get saved as they are received
</div>

</div>

\

# Saving Values to a Local Database

Use `ca_getvals_db()` Instead of `ca_getvals_tbl()`

<div style="margin-left:1em;">
- downloaded values will be saved into SQLite database as you go  
- slow connection? No problem - it will chug away on its own   
- disconnected? No problem - it will pick up where it left off     
- get back a remote tibble connected to the SQLite database  
- additional caladaptR functions help you view contents of the SQLite database, manage indices, etc.  
- standard dplyr verbs work thanks to <a href="https://dbplyr.tidyverse.org/" target="_blank" rel="noopener">dbplyr</a>
</div>

Sample usage:

<div class="indented1 indented1r">
```
my_vals <- my_api_req %>% 
  ca_getvals_db(db_fn = "my_data.sqlite",
                db_tbl = "daily_vals",
                new_recs_only = TRUE)
```
</div>

<div class="indented1">
`new_recs_only = TRUE` &rarr; will pick up where it left off if the connection interrupted  

`ca_getvals_db()` returns a 'remote tibble' linked to a local database

Work with 'remote tibbles' using many of the same techniques as regular tibbles (with a few exceptions)

`ca_db_info()` and `ca_db_indices()` help you view and manage database files

See the [*Large Queries*](https://ucanr-igis.github.io/caladaptr/articles/large-queries.html){target="_blank" rel="noopener"} Vignette for details
</div>

\

# Notebook 3: Large Queries

<div class="indented2">

In Notebook 3 you will:

<div class="indented2">
- query using a sf polygon object
- download climate values into a SQLite database  
- summarize the values in a remote tibble with dplyr statements  
</div>

[Notebook 3. Large Queries and Rasters](./notebooks/nb03_large-queries.nb.html){target="_blank" rel="noopener"} | [solutions](./notebooks/nb03_large-queries_ans.nb.html){target="_blank" rel="noopener"}

</div>

# END!
